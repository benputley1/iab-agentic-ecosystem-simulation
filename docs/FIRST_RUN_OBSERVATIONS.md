# First Run Observations - 30 Day Simulation

> Documentation of the initial simulation run and observations for improvement

**Run Date:** 2026-01-30  
**Mode:** Mock LLM (deterministic)  
**Duration:** 30 simulated days  
**Campaigns:** 50 (5 buyers Ã— 10 campaigns each)

---

## Execution Summary

### What Worked âœ…

1. **Three-scenario comparison framework** executed successfully
2. **Discrepancy injection** produced realistic distributions matching industry data
3. **Context rot simulation** tracked 32 loss events, 7 hallucinations
4. **Fee calculation** accurately modeled 15% exchange extraction
5. **CLI tooling** (`rtb-sim run/compare`) functional

### Infrastructure Gaps ðŸ”§

1. **PostgreSQL not fully provisioned** on Railway
   - Ground truth tables not created
   - Ledger tables for Scenario C unavailable
   - Workaround: Used mock repositories

2. **LLM provider initialization** attempted even in mock mode
   - Required dummy API key workaround
   - Fix: Better environment detection

3. **Reconciliation module config** had missing attributes
   - Patched during run
   - Fix: Complete config validation

---

## Key Observations

### Discrepancy Model Calibration

The model produced realistic results matching industry benchmarks:

| Metric | Simulated | Industry Benchmark | Source |
|--------|-----------|-------------------|--------|
| Average discrepancy | 8.2% | 5-15% | ISBA 2020 |
| Campaigns >5% | 42% | ~40% | ANA 2023 |
| Campaigns >15% | 18% | 10-20% | Estimated |
| Unresolvable rate | 18% | 12-18% | Hypothesis |

### Context Rot Progression

Decay followed expected exponential curve:
- Day 1-7: ~3% divergence (grace period)
- Day 8-15: ~8% divergence (accumulating)
- Day 16-30: ~15% divergence (problematic)

### Scenario Comparison

| Metric | A (Exchange) | B (IAB A2A) | C (Alkimi) |
|--------|--------------|-------------|------------|
| Fees | 15% | 0%* | 0.1% |
| Disputes | 5% | 20% | 0% |
| Unresolvable | 0% | 18% | 0% |
| Resolution | 7-14 days | 45+ days | Instant |

*Note: IAB A2A "0%" ignores hidden costs (see below)

---

## Critical Additions for v2 (Ben's Points)

### 1. IAB A2A Hidden Costs

The "0% fees" claim is misleading. A2A incurs:

| Cost Type | Estimated |
|-----------|-----------|
| LLM API calls (~$0.01-0.10/decision) | 1-3% of spend |
| Agent infrastructure | $10-50K/month |
| Manual reconciliation labor | 2-5% of disputed spend |
| Legal/arbitration | Variable |

**Recommendation:** Model "Total Cost of Ownership" not just transaction fees.

### 2. Scenario A Also Has Context Rot

Exchanges are building agentic systems too. Their arbitration logs:
- Generated by AI agents with same context limits
- Subject to same hallucination risks
- If exchange AI hallucinates, it becomes "ground truth"

**Implication:** Even centralized arbiters need immutable ground truth.

**Recommendation:** Add Scenario A' that models exchange-side context rot.

### 3. Real Pricing Data Needed

Current pricing uses synthetic distributions. For accuracy, integrate:
- Walrus blob: `59_gYePUhbvdQDRI2VUnwxZ5qwpw8eZOdWLmEmp6Pp4` (~2,000 real ad transactions)
- Sui txn: `0x7028e68c3fc036dd0e1d63b298505bb9bf034da5f3080c893500676731b46235`

**Status:** Blob requires direct API access (aggregators returning empty)

---

## Improvements for Next Run

### Must Have

1. [ ] Real LLM calls (Claude API) for actual decision variance
2. [ ] PostgreSQL fully provisioned for ground truth
3. [ ] Integrate real pricing data from Walrus blob
4. [ ] Model IAB A2A hidden costs (LLM, infrastructure, labor)
5. [ ] Add exchange-side context rot (Scenario A')

### Nice to Have

1. [ ] Extended duration (90 days) for compounding effects
2. [ ] Sensitivity analysis on decay rates (0.5%, 2%, 5%)
3. [ ] Adversarial agent scenarios
4. [ ] Network effects with 20+ agents

---

## Files Generated This Run

| File | Description |
|------|-------------|
| `SIMULATION_RESULTS_30DAY.md` | Full results report |
| `KEY_FINDINGS.md` | Executive talking points |
| `docs/GASTOWN_BUILD_PROCESS.md` | How the sim was built |
| `docs/FIRST_RUN_OBSERVATIONS.md` | This document |

---

## Gastown Meta-Observation

The simulation was itself built by AI agents (polecats) working in parallel. This demonstrates the thesis at a meta level:

- 15+ polecats worked simultaneously
- Each maintained private state
- Coordination required explicit Beads synchronization
- Without shared records, work would have conflicted

**The build process validates the research conclusion.**

---

*Observations recorded 2026-01-30 by NJ*
